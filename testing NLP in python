
# coding: utf-8

# In[ ]:


import nltk


# In[ ]:


nltk.download()


# In[ ]:


from nltk.tokenize import sent_tokenize


# In[ ]:


sent_tokenize("Ashley is learning python. OMG.")


# In[ ]:


from nltk.tokenize import word_tokenize


# In[ ]:


word_tokenize('Ashley is learning python. OMG.')


# In[ ]:


word_tokenize("What's up?")


# In[43]:


train = pd.read_csv('train_E6oV3lV.csv')


# In[44]:


train['word_count'] = train['tweet'].apply(lambda x: len(str(x).split(" ")))
train[['tweet','word_count']].head()


# In[45]:


train['tweet'] = train['tweet'].apply(lambda x: " ".join(x.lower() for x in x.split()))
train['tweet'].head()


# In[46]:


train['tweet'] = train['tweet'].str.replace('[^\w\s]','')
train['tweet'].head()


# In[47]:


from nltk.corpus import stopwords
stop = stopwords.words('english')
train['tweet'] = train['tweet'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))
train['tweet'].head()


# In[48]:


freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[:10]
freq


# In[49]:


freq = list(freq.index)
train['tweet'] = train['tweet'].apply(lambda x: " ".join(x for x in x.split() if x not in freq))
train['tweet'].head()


# In[50]:


freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[-10:]
freq


# In[51]:


freq = list(freq.index)
train['tweet'] = train['tweet'].apply(lambda x: " ".join(x for x in x.split() if x not in freq))
train['tweet'].head()


# In[52]:


import textblob


# In[53]:


from textblob import TextBlob
train['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))


# In[54]:


TextBlob(train['tweet'][1]).words


# In[55]:


from nltk.stem import PorterStemmer
st = PorterStemmer()
train['tweet'][:5].apply(lambda x: " ".join([st.stem(word) for word in x.split()]))


# In[56]:


from textblob import Word
train['tweet'] = train['tweet'].apply(lambda x: " ".join([Word(word).lemmatize() for word in x.split()]))
train['tweet'].head()


# In[57]:


TextBlob(train['tweet'][0]).ngrams(2)


# In[ ]:


TextBlob(train['tweet'][0]).ngrams(3)


# In[58]:


tf1 = (train['tweet'][1:2]).apply(lambda x: pd.value_counts(x.split(" "))).sum(axis = 0).reset_index()
tf1.columns = ['words','tf']
tf1


# In[59]:


import numpy as np


# In[60]:


for i,word in enumerate(tf1['words']):
  tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['tweet'].str.contains(word)])))

tf1


# In[61]:


tf1['tfidf'] = tf1['tf'] * tf1['idf']
tf1


# In[62]:


from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',
 stop_words= 'english',ngram_range=(1,1))
train_vect = tfidf.fit_transform(train['tweet'])

train_vect


# In[63]:


from sklearn.feature_extraction.text import CountVectorizer
bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = "word")
train_bow = bow.fit_transform(train['tweet'])
train_bow


# In[65]:


train['tweet'][:5].apply(lambda x: TextBlob(x).sentiment)
#nearer to one is positive; nearer to to -1 is negative


# In[66]:


train['sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )
train[['tweet','sentiment']].head()


# In[73]:


from nltk.corpus import wordnet
 
synonyms = []
 
for syn in wordnet.synsets('technology'):
 
    for lemma in syn.lemmas():
 
        synonyms.append(lemma.name())
 
print(synonyms)


# In[81]:


traina = pd.read_csv('boca.csv')


# In[86]:


traina['word_count'] = traina['tweet'].apply(lambda x: len(str(x).split(" ")))
traina[['tweet','word_count']].head()


# In[94]:


traina['tweet'] = traina['tweet'].apply(lambda x: " ".join(str(x).lower() for x in str(x).split()))
traina['tweet'].head()
#had to wrap x in string so that code knew not to look at number columns


# In[95]:


traina['tweet'] = traina['tweet'].str.replace('[^\w\s]','')
traina['tweet'].head()


# In[97]:


from nltk.corpus import stopwords
stop = stopwords.words('english')
traina['tweet'] = traina['tweet'].apply(lambda x: " ".join(str(x) for x in str(x).split() if x not in stop))
traina['tweet'].head()


# In[99]:


freq = pd.Series(' '.join(traina['tweet']).split()).value_counts()[:10]
freq


# In[100]:


freq = list(freq.index)
traina['tweet'] = traina['tweet'].apply(lambda x: " ".join(str(x) for x in str(x).split() if x not in freq))
traina['tweet'].head()


# In[105]:


freq = pd.Series(' '.join(traina['tweet']).split()).value_counts()[-10:]
freq


# In[106]:


freq = list(freq.index)
traina['tweet'] = traina['tweet'].apply(lambda x: " ".join(str(x) for x in str(x).split() if x not in freq))
traina['tweet'].head()


# In[129]:


from textblob import TextBlob
traina['tweet'].apply(lambda x: str(TextBlob(x).correct()))


# In[141]:


for word in TextBlob(traina['tweet'][1]).words:
    print(word)

